{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9097589-452f-4e7f-8351-2e588224ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages (uncomment for one-time installs)\n",
    "# !pip install ultralytics opencv-python numpy easyocr customtkinter requests pillow\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import threading\n",
    "import re\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageTk\n",
    "import customtkinter as ctk\n",
    "import tkinter as tk\n",
    "\n",
    "# -------------------------\n",
    "# LicensePlateDetector (Refactored detection logic)\n",
    "# -------------------------\n",
    "class LicensePlateDetector:\n",
    "    def __init__(self,\n",
    "                 car_model_path=\"yolov8n.pt\",\n",
    "                 plate_model_path=\"LP-detection.pt\",\n",
    "                 superres_model_path=\"EDSR_x3.pb\",\n",
    "                 use_superres=True,\n",
    "                 burst_frame_count=5,\n",
    "                 burst_frame_interval=0.08,\n",
    "                 cooldown_period=10):\n",
    "\n",
    "        self.camera_data = {}\n",
    "        self.cap = None\n",
    "        self.is_running = False\n",
    "        self.detection_active = True\n",
    "        self.last_detection_time = None\n",
    "        self.cooldown_period = cooldown_period\n",
    "        self.detection_count = 0\n",
    "\n",
    "        self.frame_width = 0\n",
    "        self.frame_height = 0\n",
    "        self.total_frame_area = 0\n",
    "\n",
    "        self.consecutive_blank_frames = 0\n",
    "        self.max_blank_frames = 10\n",
    "\n",
    "        # Load YOLO models\n",
    "        print(\"üöÄ Loading YOLO models...\")\n",
    "        self.car_model = YOLO(car_model_path)\n",
    "        self.plate_model = YOLO(plate_model_path)\n",
    "\n",
    "        # GPU flag (ultralytics sets device automatically)\n",
    "        self.use_gpu = (self.car_model.device.type == \"cuda\")\n",
    "        print(f\"‚úÖ YOLO loaded. Device: {self.car_model.device}\")\n",
    "\n",
    "        # EasyOCR reader\n",
    "        print(\"üî§ Initializing EasyOCR reader...\")\n",
    "        try:\n",
    "            # Use GPU if available\n",
    "            self.reader = easyocr.Reader(['en'], gpu=self.use_gpu)\n",
    "            print(f\"‚úÖ EasyOCR initialized (gpu={self.use_gpu})\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è EasyOCR init failed, falling back to cpu: {e}\")\n",
    "            self.reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "        # Super-resolution\n",
    "        self.enable_superres = use_superres\n",
    "        self.superres_model_path = superres_model_path\n",
    "        self.superres_net = None\n",
    "        self.initialize_superres()\n",
    "\n",
    "        # Detection tuning\n",
    "        # gate_line_y will be set dynamically per-frame as 60% of frame height\n",
    "        self.gate_line_ratio = 0.60\n",
    "        self.min_car_width = 120\n",
    "        self.min_coverage_trigger = 2  # percent\n",
    "\n",
    "        # Burst capture\n",
    "        self.burst_frame_count = burst_frame_count\n",
    "        self.burst_frame_interval = burst_frame_interval\n",
    "\n",
    "        # Text correction map\n",
    "        self.subs_map = {\n",
    "            '0': 'O', 'O': '0', '1': 'I', 'I': '1', '8': 'B', 'B': '8',\n",
    "            '6': 'G', 'G': '6', '5': 'S', 'S': '5', '2': 'Z', 'Z': '2',\n",
    "            '4': 'A', 'A': '4', 'U': 'V', 'V': 'U', 'Q': '0'\n",
    "        }\n",
    "\n",
    "    def initialize_superres(self):\n",
    "        if not self.enable_superres:\n",
    "            return\n",
    "        try:\n",
    "            self.superres_net = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "            self.superres_net.readModel(self.superres_model_path)\n",
    "            lower = self.superres_model_path.lower()\n",
    "            if \"edsr\" in lower:\n",
    "                self.superres_net.setModel(\"edsr\", 3)\n",
    "            elif \"fsrcnn\" in lower:\n",
    "                self.superres_net.setModel(\"fsrcnn\", 4)\n",
    "            elif \"lapsrn\" in lower or \"lapsrn\" in lower:\n",
    "                self.superres_net.setModel(\"lapsrn\", 3)\n",
    "            else:\n",
    "                self.superres_net.setModel(\"edsr\", 3)\n",
    "            print(\"‚úÖ Super-resolution model loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load super-resolution model: {e}\")\n",
    "            self.superres_net = None\n",
    "            self.enable_superres = False\n",
    "\n",
    "    def enhance_with_superres(self, image):\n",
    "        try:\n",
    "            if self.enable_superres and self.superres_net is not None:\n",
    "                return self.superres_net.upsample(image)\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error in super-resolution: {e}\")\n",
    "            return image\n",
    "\n",
    "    # -------------------------\n",
    "    # Config load (cam.txt)\n",
    "    # -------------------------\n",
    "    def load_camera_config(self):\n",
    "        try:\n",
    "            with open('cam.txt', 'r') as file:\n",
    "                lines = [line.strip() for line in file.readlines() if line.strip()]\n",
    "                # safe access\n",
    "                self.camera_data = {\n",
    "                    'rtsp_url': lines[0] if len(lines) > 0 else '',\n",
    "                    'substream_url': lines[0] if len(lines) > 0 else '',\n",
    "                    'ip': lines[1].split()[1] if len(lines) > 1 and len(lines[1].split()) > 1 else '192.168.52.160',\n",
    "                    'port': lines[2].split()[1] if len(lines) > 2 and len(lines[2].split()) > 1 else '554',\n",
    "                    'id': lines[3].split()[1] if len(lines) > 3 and len(lines[3].split()) > 1 else 'admin',\n",
    "                    'password': lines[4].split()[1] if len(lines) > 4 and len(lines[4].split()) > 1 else '',\n",
    "                    'location': lines[5].split()[1] if len(lines) > 5 and len(lines[5].split()) > 1 else 'unknown',\n",
    "                    'bot_token': lines[6].split()[1] if len(lines) > 6 and len(lines[6].split()) > 1 else '',\n",
    "                    'chat_id': lines[7].split()[1] if len(lines) > 7 and len(lines[7].split()) > 1 else ''\n",
    "                }\n",
    "            print(\"Camera configuration loaded:\", self.camera_data)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading camera config: {e}\")\n",
    "            return False\n",
    "\n",
    "    # -------------------------\n",
    "    # Blank frame detection\n",
    "    # -------------------------\n",
    "    def check_blank_frame(self, frame):\n",
    "        if frame is None:\n",
    "            return True\n",
    "        if np.mean(frame) < 8:\n",
    "            return True\n",
    "        if np.std(frame) < 5:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # -------------------------\n",
    "    # YOLO-based car detection + NMS\n",
    "    # -------------------------\n",
    "    def nms(self, boxes, iou_thresh=0.4):\n",
    "        \"\"\"Simple NMS for xyxy boxes: boxes as [x1,y1,x2,y2,conf]\"\"\"\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "        boxes = sorted(boxes, key=lambda x: x[4], reverse=True)\n",
    "        filtered = []\n",
    "        while boxes:\n",
    "            chosen = boxes.pop(0)\n",
    "            filtered.append(chosen)\n",
    "            keep = []\n",
    "            for b in boxes:\n",
    "                # compute iou\n",
    "                inter_x1 = max(chosen[0], b[0])\n",
    "                inter_y1 = max(chosen[1], b[1])\n",
    "                inter_x2 = min(chosen[2], b[2])\n",
    "                inter_y2 = min(chosen[3], b[3])\n",
    "                inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "                area_chosen = (chosen[2] - chosen[0]) * (chosen[3] - chosen[1])\n",
    "                area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "                denom = float(area_chosen + area_b - inter_area) if (area_chosen + area_b - inter_area) > 0 else 1.0\n",
    "                iou = inter_area / denom\n",
    "                if iou < iou_thresh:\n",
    "                    keep.append(b)\n",
    "            boxes = keep\n",
    "        return filtered\n",
    "\n",
    "    def detect_cars_yolo(self, frame, conf_thresh=0.35, iou_thresh=0.45, imgsz=640):\n",
    "        \"\"\"Return list of car boxes in [x,y,w,h,area] format\"\"\"\n",
    "        boxes_out = []\n",
    "        try:\n",
    "            results = self.car_model.predict(source=frame, conf=conf_thresh, iou=iou_thresh, imgsz=imgsz, verbose=False)\n",
    "            all_boxes = []\n",
    "            if results and len(results[0].boxes) > 0:\n",
    "                for r in results:\n",
    "                    for box in r.boxes:\n",
    "                        cls_id = int(box.cls[0].item())\n",
    "                        conf = float(box.conf[0].item())\n",
    "                        # COCO class ids: 2 = car, 3 = motorcycle, 5 = bus, 7 = truck\n",
    "                        if cls_id in [2, 3, 5, 7]:\n",
    "                            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                            area = (x2 - x1) * (y2 - y1)\n",
    "                            all_boxes.append([x1, y1, x2, y2, conf, area])\n",
    "            # convert to [x1,y1,x2,y2,conf] for nms\n",
    "            nms_input = [[b[0], b[1], b[2], b[3], b[4]] for b in all_boxes]\n",
    "            nmsed = self.nms(nms_input, iou_thresh=0.4)\n",
    "            # convert to desired output format and filter by min area\n",
    "            for x1, y1, x2, y2, conf in nmsed:\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                area = w * h\n",
    "                boxes_out.append((x1, y1, w, h, area))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in detect_cars_yolo: {e}\")\n",
    "        return boxes_out\n",
    "\n",
    "    # -------------------------\n",
    "    # Plate detection with YOLO + merge\n",
    "    # -------------------------\n",
    "    def merge_boxes(self, boxes, iou_thresh=0.4):\n",
    "        \"\"\"Merge overlapping YOLO boxes that likely belong to the same plate.\n",
    "           boxes: list of [x1,y1,x2,y2,conf]\"\"\"\n",
    "        if not boxes:\n",
    "            return []\n",
    "        boxes = sorted(boxes, key=lambda x: x[4], reverse=True)\n",
    "        merged = []\n",
    "        while boxes:\n",
    "            base = boxes.pop(0)\n",
    "            x1b, y1b, x2b, y2b, confb = base\n",
    "            keep = [base]\n",
    "            remove_idx = []\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2, conf = box\n",
    "                inter_x1 = max(x1, x1b)\n",
    "                inter_y1 = max(y1, y1b)\n",
    "                inter_x2 = min(x2, x2b)\n",
    "                inter_y2 = min(y2, y2b)\n",
    "                inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "                area1 = (x2 - x1) * (y2 - y1)\n",
    "                area2 = (x2b - x1b) * (y2b - y1b)\n",
    "                denom = (area1 + area2 - inter_area) if (area1 + area2 - inter_area) > 0 else 1.0\n",
    "                iou = inter_area / denom\n",
    "                if iou > iou_thresh:\n",
    "                    keep.append(box)\n",
    "                    remove_idx.append(i)\n",
    "            for idx in sorted(remove_idx, reverse=True):\n",
    "                boxes.pop(idx)\n",
    "            merged_box = [\n",
    "                min(b[0] for b in keep),\n",
    "                min(b[1] for b in keep),\n",
    "                max(b[2] for b in keep),\n",
    "                max(b[3] for b in keep),\n",
    "                max(b[4] for b in keep)\n",
    "            ]\n",
    "            merged.append(merged_box)\n",
    "        return merged\n",
    "\n",
    "    def detect_plates_yolo(self, frame, car_box=None, conf_thresh=0.18, iou_thresh=0.45, imgsz=960):\n",
    "        \"\"\"\n",
    "        Run plate model either on whole frame or ROI (car_box).\n",
    "        Returns best plate box (x,y,w,h) or None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if car_box:\n",
    "                x, y, w, h, area = car_box\n",
    "                pad_w = int(0.12 * w)\n",
    "                pad_h = int(0.12 * h)\n",
    "                x1 = max(0, x - pad_w)\n",
    "                y1 = max(0, y - pad_h)\n",
    "                x2 = min(frame.shape[1], x + w + pad_w)\n",
    "                y2 = min(frame.shape[0], y + h + pad_h)\n",
    "                roi = frame[y1:y2, x1:x2]\n",
    "                if roi is None or roi.size == 0:\n",
    "                    return None\n",
    "                results = self.plate_model.predict(source=roi, conf=conf_thresh, iou=iou_thresh, imgsz=imgsz, verbose=False)\n",
    "                plate_boxes = []\n",
    "                for r in results:\n",
    "                    for box in r.boxes:\n",
    "                        xA, yA, xB, yB = map(int, box.xyxy[0])\n",
    "                        conf = float(box.conf[0].item())\n",
    "                        abs_x1 = x1 + xA\n",
    "                        abs_y1 = y1 + yA\n",
    "                        abs_x2 = x1 + xB\n",
    "                        abs_y2 = y1 + yB\n",
    "                        plate_boxes.append([abs_x1, abs_y1, abs_x2, abs_y2, conf])\n",
    "            else:\n",
    "                results = self.plate_model.predict(source=frame, conf=conf_thresh, iou=iou_thresh, imgsz=imgsz, verbose=False)\n",
    "                plate_boxes = []\n",
    "                for r in results:\n",
    "                    for box in r.boxes:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        conf = float(box.conf[0].item())\n",
    "                        plate_boxes.append([x1, y1, x2, y2, conf])\n",
    "\n",
    "            if not plate_boxes:\n",
    "                return None\n",
    "\n",
    "            merged = self.merge_boxes(plate_boxes, iou_thresh=0.35)\n",
    "\n",
    "            best = None\n",
    "            for (x1m, y1m, x2m, y2m, confm) in merged:\n",
    "                w_m = x2m - x1m\n",
    "                h_m = y2m - y1m\n",
    "                if h_m <= 0:\n",
    "                    continue\n",
    "                ar = w_m / float(h_m)\n",
    "                if 1.0 <= ar <= 7.0 and w_m > 30 and h_m > 10:\n",
    "                    best = (x1m, y1m, w_m, h_m)\n",
    "                    break\n",
    "\n",
    "            if best is None:\n",
    "                merged_sorted = sorted(merged, key=lambda b: b[4], reverse=True)\n",
    "                if merged_sorted:\n",
    "                    x1m, y1m, x2m, y2m, confm = merged_sorted[0]\n",
    "                    best = (x1m, y1m, x2m - x1m, y2m - y1m)\n",
    "\n",
    "            return best\n",
    "        except Exception as e:\n",
    "            print(f\"Error in detect_plates_yolo: {e}\")\n",
    "            return None\n",
    "\n",
    "    # -------------------------\n",
    "    # Preprocess plate image and OCR using EasyOCR (with multiple attempts)\n",
    "    # -------------------------\n",
    "    def preprocess_plate_image(self, plate_image):\n",
    "        try:\n",
    "            if plate_image is None or plate_image.size == 0:\n",
    "                return []\n",
    "\n",
    "            # Try super-resolution first if enabled\n",
    "            try:\n",
    "                if self.enable_superres and self.superres_net is not None:\n",
    "                    plate_image = self.superres_net.upsample(plate_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Super-res skipped: {e}\")\n",
    "\n",
    "            # Ensure color -> gray\n",
    "            gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Resize (scale up) to improve OCR\n",
    "            gray = cv2.resize(gray, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Denoise + sharpen + contrast\n",
    "            gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "            gray = cv2.equalizeHist(gray)\n",
    "            gray = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "            gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=15)\n",
    "            kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "            gray = cv2.filter2D(gray, -1, kernel)\n",
    "\n",
    "            # Binary versions\n",
    "            _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "            return [gray, thresh, adaptive]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in image preprocessing: {e}\")\n",
    "            return []\n",
    "\n",
    "    def correct_text(self, text):\n",
    "        text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "        corrected = ''.join([self.subs_map.get(ch, ch) for ch in text])\n",
    "        # conservative pattern for Indian plates - lenient in case of partial reads\n",
    "        pattern = r'[A-Z]{2}\\d{1,2}[A-Z]{0,3}\\d{1,4}'\n",
    "        if not re.fullmatch(pattern, corrected):\n",
    "            # try replacements again\n",
    "            for k, v in self.subs_map.items():\n",
    "                corrected = corrected.replace(k, v)\n",
    "        return corrected\n",
    "\n",
    "    def extract_text_from_plate(self, plate_image):\n",
    "        try:\n",
    "            if plate_image is None or plate_image.size == 0:\n",
    "                return None\n",
    "            preprocessed_imgs = self.preprocess_plate_image(plate_image)\n",
    "            if not preprocessed_imgs:\n",
    "                return None\n",
    "\n",
    "            text_found = None\n",
    "            # Try multiple preprocessed images\n",
    "            for ocr_img in preprocessed_imgs:\n",
    "                try:\n",
    "                    ocr_result = self.reader.readtext(ocr_img, detail=0, paragraph=False)\n",
    "                except Exception as e:\n",
    "                    try:\n",
    "                        ocr_result = self.reader.readtext(cv2.cvtColor(ocr_img, cv2.COLOR_GRAY2BGR), detail=0, paragraph=False)\n",
    "                    except Exception:\n",
    "                        ocr_result = []\n",
    "                if ocr_result:\n",
    "                    text_found = max(ocr_result, key=len)\n",
    "                    break\n",
    "\n",
    "            if not text_found:\n",
    "                return None\n",
    "\n",
    "            text_clean = self.correct_text(text_found)\n",
    "            if 2 <= len(text_clean) <= 15:\n",
    "                return text_clean\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error in text extraction: {e}\")\n",
    "            return None\n",
    "\n",
    "    # -------------------------\n",
    "    # Save images, send telegram\n",
    "    # -------------------------\n",
    "    def save_detection_images(self, frame, car_region, plate_region, plate_text, coverage_percentage):\n",
    "        try:\n",
    "            annotated_frame = frame.copy()\n",
    "            car_x, car_y, car_w, car_h, car_area = car_region\n",
    "            cv2.rectangle(annotated_frame, (car_x, car_y), (car_x + car_w, car_y + car_h), (0, 255, 255), 2)\n",
    "\n",
    "            if plate_region:\n",
    "                px, py, pw, ph = plate_region\n",
    "                cv2.rectangle(annotated_frame, (px, py), (px + pw, py + ph), (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(annotated_frame, f\"Coverage: {coverage_percentage}%\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            cv2.putText(annotated_frame, f\"Plate: {plate_text}\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            cv2.putText(annotated_frame, f\"Location: {self.camera_data.get('location','-')}\", (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.putText(annotated_frame, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), (10, 110),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            full_filename = f\"full_detection_{self.detection_count}.jpg\"\n",
    "            closeup_filename = f\"closeup_{self.detection_count}.jpg\"\n",
    "\n",
    "            cv2.imwrite(full_filename, annotated_frame)\n",
    "\n",
    "            if plate_region:\n",
    "                px, py, pw, ph = plate_region\n",
    "                plate_closeup = frame[py:py + ph, px:px + pw]\n",
    "                if plate_closeup.size > 0:\n",
    "                    closeup_enhanced = cv2.resize(plate_closeup, (int(pw * 3), int(ph * 3)), interpolation=cv2.INTER_CUBIC)\n",
    "                    cv2.imwrite(closeup_filename, closeup_enhanced)\n",
    "                else:\n",
    "                    car_closeup = frame[car_y:car_y + car_h, car_x:car_x + car_w]\n",
    "                    car_closeup = cv2.resize(car_closeup, (300, 200), interpolation=cv2.INTER_CUBIC)\n",
    "                    cv2.putText(car_closeup, \"Plate Not Detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    cv2.imwrite(closeup_filename, car_closeup)\n",
    "            else:\n",
    "                car_closeup = frame[car_y:car_y + car_h, car_x:car_x + car_w]\n",
    "                car_closeup = cv2.resize(car_closeup, (300, 200), interpolation=cv2.INTER_CUBIC)\n",
    "                cv2.putText(car_closeup, \"Plate Not Detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.imwrite(closeup_filename, car_closeup)\n",
    "\n",
    "            return full_filename, closeup_filename\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving images: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def send_to_telegram(self, full_image_path, closeup_image_path, plate_text, coverage_percentage):\n",
    "        try:\n",
    "            bot = self.camera_data.get('bot_token')\n",
    "            chat = self.camera_data.get('chat_id')\n",
    "            if not bot or not chat:\n",
    "                print(\"Telegram bot token or chat id missing.\")\n",
    "                return False\n",
    "\n",
    "            url = f\"https://api.telegram.org/bot{bot}/sendMediaGroup\"\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            caption = f\"üöô Detection #{self.detection_count}\\n\"\n",
    "            caption += f\"üìç {self.camera_data.get('location','-')}\\n\"\n",
    "            caption += f\"üìÖ {current_time}\\n\"\n",
    "            caption += f\"üìè Coverage: {coverage_percentage}%\\n\"\n",
    "            caption += f\"üî¢ Plate: `{plate_text}`\"\n",
    "\n",
    "            media = [\n",
    "                {'type': 'photo', 'media': 'attach://full_image.jpg', 'caption': caption, 'parse_mode': 'Markdown'},\n",
    "                {'type': 'photo', 'media': 'attach://closeup_image.jpg'}\n",
    "            ]\n",
    "            files = {\n",
    "                'full_image.jpg': open(full_image_path, 'rb'),\n",
    "                'closeup_image.jpg': open(closeup_image_path, 'rb')\n",
    "            }\n",
    "            data = {'chat_id': chat, 'media': json.dumps(media)}\n",
    "            response = requests.post(url, files=files, data=data)\n",
    "            files['full_image.jpg'].close()\n",
    "            files['closeup_image.jpg'].close()\n",
    "            if response.status_code == 200:\n",
    "                print(f\"‚úÖ Alert sent: {plate_text}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ùå Telegram error: {response.text}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error sending to Telegram: {e}\")\n",
    "            return False\n",
    "\n",
    "    # -------------------------\n",
    "    # Burst capture\n",
    "    # -------------------------\n",
    "    def capture_burst_frames(self, cap, count=5, interval=0.08):\n",
    "        frames = []\n",
    "        try:\n",
    "            for _ in range(count):\n",
    "                ret, f = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frames.append(f.copy())\n",
    "                time.sleep(interval)\n",
    "            return frames\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Burst capture failed: {e}\")\n",
    "            return frames\n",
    "\n",
    "    # -------------------------\n",
    "    # Main per-frame processing (YOLO core + gate-line trigger)\n",
    "    # -------------------------\n",
    "    def process_frame(self, frame):\n",
    "        if not self.detection_active:\n",
    "            return frame, None, None, None, 0\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        if self.last_detection_time and (current_time - self.last_detection_time).seconds < self.cooldown_period:\n",
    "            return frame, None, None, None, 0\n",
    "\n",
    "        try:\n",
    "            self.frame_height, self.frame_width = frame.shape[:2]\n",
    "            self.total_frame_area = self.frame_width * self.frame_height\n",
    "\n",
    "            # dynamic gate line (60% of frame height)\n",
    "            self.gate_line_y = int(self.frame_height * self.gate_line_ratio)\n",
    "\n",
    "            if self.check_blank_frame(frame):\n",
    "                self.consecutive_blank_frames += 1\n",
    "                if self.consecutive_blank_frames >= self.max_blank_frames:\n",
    "                    raise Exception(\"Camera stream stuck/blank\")\n",
    "                return frame, None, None, None, 0\n",
    "            else:\n",
    "                self.consecutive_blank_frames = 0\n",
    "\n",
    "            # 1) detect cars using YOLO + NMS\n",
    "            car_boxes = self.detect_cars_yolo(frame)\n",
    "            # annotate for debug gate-line\n",
    "            cv2.line(frame, (0, self.gate_line_y), (self.frame_width, self.gate_line_y), (255, 0, 0), 2)\n",
    "\n",
    "            for car_box in car_boxes:\n",
    "                x, y, w, h, area = car_box\n",
    "                coverage_percentage = round((area / float(self.total_frame_area)) * 100, 2) if self.total_frame_area > 0 else 0\n",
    "                car_center_y = y + h // 2\n",
    "\n",
    "                # Gate-line trigger or large car or coverage threshold\n",
    "                if (car_center_y >= self.gate_line_y or w >= self.min_car_width or coverage_percentage >= self.min_coverage_trigger):\n",
    "                    print(f\"üöó Triggered: coverage={coverage_percentage}%\")\n",
    "                    self.last_detection_time = current_time\n",
    "\n",
    "                    # 2) detect plate inside car ROI\n",
    "                    plate_region = self.detect_plates_yolo(frame, (x, y, w, h, area))\n",
    "                    plate_text = None\n",
    "                    if plate_region:\n",
    "                        px, py, pw, ph = plate_region\n",
    "                        plate_image = frame[py:py + ph, px:px + pw]\n",
    "                        plate_text = self.extract_text_from_plate(plate_image)\n",
    "                        if plate_text:\n",
    "                            print(f\"üî¢ Plate read: {plate_text}\")\n",
    "\n",
    "                    self.detection_count += 1\n",
    "                    self.last_detection_time = current_time\n",
    "\n",
    "                    # burst capture (choose best sharp frame)\n",
    "                    if hasattr(self, \"cap\") and self.cap is not None and self.cap.isOpened():\n",
    "                        burst_frames = self.capture_burst_frames(self.cap, self.burst_frame_count, self.burst_frame_interval)\n",
    "                    else:\n",
    "                        burst_frames = [frame.copy()]\n",
    "\n",
    "                    best_frame = max(burst_frames, key=lambda f: cv2.Laplacian(cv2.cvtColor(f, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()) if burst_frames else frame.copy()\n",
    "                    frame = best_frame.copy()\n",
    "\n",
    "                    # spawn worker thread to save/send\n",
    "                    threading.Thread(\n",
    "                        target=self.handle_detection,\n",
    "                        args=(frame.copy(), (x, y, w, h, area), plate_region, plate_text, coverage_percentage),\n",
    "                        daemon=True\n",
    "                    ).start()\n",
    "\n",
    "                    return frame, (x, y, w, h, area), plate_region, plate_text, coverage_percentage\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"Too far ({int(coverage_percentage)}%)\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame: {e}\")\n",
    "            raise e\n",
    "\n",
    "        return frame, None, None, None, 0\n",
    "\n",
    "    def handle_detection(self, frame, car_region, plate_region, plate_text, coverage_percentage):\n",
    "        try:\n",
    "            print(f\"üéØ Detected (coverage {coverage_percentage}%) | Plate: {plate_text or 'NOT DETECTED'}\")\n",
    "            full_image_path, closeup_image_path = self.save_detection_images(frame, car_region, plate_region, plate_text or \"NOT DETECTED\", coverage_percentage)\n",
    "            if full_image_path and closeup_image_path:\n",
    "                sent = self.send_to_telegram(full_image_path, closeup_image_path, plate_text or \"NOT DETECTED\", coverage_percentage)\n",
    "                if sent:\n",
    "                    print(f\"‚úÖ Detection #{self.detection_count} processed.\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Detection #{self.detection_count} send failed.\")\n",
    "                # cleanup\n",
    "                try:\n",
    "                    os.remove(full_image_path)\n",
    "                    os.remove(closeup_image_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: could not delete temp images: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error handling detection: {e}\")\n",
    "\n",
    "# -------------------------\n",
    "# GUI (LicensePlateGUI) - unchanged visually, uses new detector underneath\n",
    "# -------------------------\n",
    "class LicensePlateGUI:\n",
    "    def __init__(self, root):\n",
    "        ctk.set_appearance_mode(\"Dark\")\n",
    "        ctk.set_default_color_theme(\"blue\")\n",
    "\n",
    "        self.root = root\n",
    "        self.root.title(\"üöó Car Detection Dashboard\")\n",
    "        self.root.geometry(\"720x480\")\n",
    "        self.root.resizable(False, False)\n",
    "        self.root.attributes('-topmost', True)\n",
    "\n",
    "        # Detector backend\n",
    "        self.detector = LicensePlateDetector()\n",
    "\n",
    "        self.car_count = 0\n",
    "        self.setup_gui()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.main_frame = ctk.CTkFrame(self.root, corner_radius=10)\n",
    "        self.main_frame.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "        header_frame = ctk.CTkFrame(self.main_frame, fg_color=\"transparent\")\n",
    "        header_frame.pack(fill=\"x\", pady=(5, 0))\n",
    "        self.title_label = ctk.CTkLabel(header_frame, text=\"Car Detection Live Stream\", font=ctk.CTkFont(size=18, weight=\"bold\"))\n",
    "        self.title_label.pack(side=\"left\", padx=10)\n",
    "        self.theme_switch = ctk.CTkSwitch(header_frame, text=\"Light Mode\", command=self.toggle_theme)\n",
    "        self.theme_switch.pack(side=\"right\", padx=10)\n",
    "\n",
    "        video_frame = ctk.CTkFrame(self.main_frame, corner_radius=10)\n",
    "        video_frame.pack(fill=\"both\", expand=True, pady=10, padx=10)\n",
    "\n",
    "        self.counter_label = ctk.CTkLabel(video_frame, text=\"Cars: 0\", font=ctk.CTkFont(size=13, weight=\"bold\"),\n",
    "                                          fg_color=\"#1E88E5\", text_color=\"white\", corner_radius=8, padx=10, pady=3)\n",
    "        self.counter_label.place(x=10, y=10)\n",
    "\n",
    "        self.video_label = ctk.CTkLabel(video_frame, text=\"Camera feed offline.\\nPress Start to begin.\",\n",
    "                                        font=ctk.CTkFont(size=13), height=280, corner_radius=8,\n",
    "                                        fg_color=(\"gray90\", \"#2b2b2b\"), justify=\"center\")\n",
    "        self.video_label.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "        controls_frame = ctk.CTkFrame(self.main_frame, fg_color=\"transparent\")\n",
    "        controls_frame.pack(fill=\"x\", pady=(0, 5))\n",
    "\n",
    "        self.start_btn = ctk.CTkButton(controls_frame, text=\"Start\", width=80, command=self.start_detection)\n",
    "        self.start_btn.pack(side=\"left\", padx=5)\n",
    "        self.pause_btn = ctk.CTkButton(controls_frame, text=\"Pause\", width=80, command=self.toggle_detection)\n",
    "        self.pause_btn.pack(side=\"left\", padx=5)\n",
    "        self.stop_btn = ctk.CTkButton(controls_frame, text=\"Stop\", width=80, command=self.stop_detection, state=\"disabled\")\n",
    "        self.stop_btn.pack(side=\"left\", padx=5)\n",
    "\n",
    "        bottom_frame = ctk.CTkFrame(self.main_frame, fg_color=\"transparent\")\n",
    "        bottom_frame.pack(fill=\"x\", pady=(5, 0))\n",
    "\n",
    "        self.status_label = ctk.CTkLabel(bottom_frame, text=\"Status: Idle\", text_color=\"orange\", font=ctk.CTkFont(size=12, weight=\"bold\"))\n",
    "        self.status_label.pack(side=\"left\", padx=10)\n",
    "        self.log_label = ctk.CTkLabel(bottom_frame, text=\"Ready - Integrated YOLO + EasyOCR\", font=ctk.CTkFont(size=11), text_color=\"gray\")\n",
    "        self.log_label.pack(side=\"right\", padx=10)\n",
    "\n",
    "    def toggle_theme(self):\n",
    "        if self.theme_switch.get():\n",
    "            ctk.set_appearance_mode(\"Light\")\n",
    "            self.theme_switch.configure(text=\"Dark Mode\")\n",
    "        else:\n",
    "            ctk.set_appearance_mode(\"Dark\")\n",
    "            self.theme_switch.configure(text=\"Light Mode\")\n",
    "\n",
    "    def log_message(self, message):\n",
    "        short_msg = message[:60] + \"...\" if len(message) > 60 else message\n",
    "        self.log_label.configure(text=short_msg)\n",
    "        self.root.update()\n",
    "\n",
    "    def start_detection(self):\n",
    "        try:\n",
    "            if not self.detector.load_camera_config():\n",
    "                self.log_message(\"‚ùå Config load failed\")\n",
    "                return\n",
    "\n",
    "            self.log_message(\"üìã Loading camera...\")\n",
    "\n",
    "            substream = self.detector.camera_data.get('substream_url') or self.detector.camera_data.get('rtsp_url')\n",
    "            self.detector.cap = cv2.VideoCapture(substream)\n",
    "            self.detector.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            self.detector.cap.set(cv2.CAP_PROP_FPS, 18)\n",
    "            self.detector.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "            self.detector.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)\n",
    "\n",
    "            if not self.detector.cap.isOpened():\n",
    "                self.log_message(\"‚ùå Camera connect failed\")\n",
    "                return\n",
    "\n",
    "            self.detector.is_running = True\n",
    "            self.start_btn.configure(state=\"disabled\")\n",
    "            self.stop_btn.configure(state=\"normal\")\n",
    "            self.status_label.configure(text=\"Status: Running\", text_color=\"green\")\n",
    "            self.log_message(\"‚úÖ System started - Hybrid YOLO + EasyOCR (gate-line preserved)\")\n",
    "\n",
    "            # attach cap to detector for burst capture\n",
    "            self.detector.cap = self.detector.cap\n",
    "            self.process_video()\n",
    "        except Exception as e:\n",
    "            self.log_message(f\"‚ùå Start error: {str(e)[:60]}\")\n",
    "\n",
    "    def stop_detection(self):\n",
    "        self.detector.is_running = False\n",
    "        if self.detector.cap:\n",
    "            try:\n",
    "                self.detector.cap.release()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self.detector.cap = None\n",
    "\n",
    "        self.start_btn.configure(state=\"normal\")\n",
    "        self.stop_btn.configure(state=\"disabled\")\n",
    "        self.status_label.configure(text=\"Status: Stopped\", text_color=\"red\")\n",
    "        self.video_label.configure(image='', text=\"Camera feed offline.\\nPress Start to begin.\")\n",
    "        self.log_message(\"‚èπ System stopped\")\n",
    "\n",
    "    def toggle_detection(self):\n",
    "        self.detector.detection_active = not self.detector.detection_active\n",
    "        status = \"ACTIVE\" if self.detector.detection_active else \"PAUSED\"\n",
    "        color = \"green\" if self.detector.detection_active else \"orange\"\n",
    "        self.pause_btn.configure(text=\"Resume\" if not self.detector.detection_active else \"Pause\")\n",
    "        self.status_label.configure(text=f\"Status: {status}\", text_color=color)\n",
    "        self.log_message(f\"‚è∏ Detection {status.lower()}\")\n",
    "\n",
    "    def process_video(self):\n",
    "        if not self.detector.is_running or not self.detector.cap:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            ret, frame = self.detector.cap.read()\n",
    "            if ret:\n",
    "                processed_frame, car_region, plate_region, plate_text, coverage = self.detector.process_frame(frame)\n",
    "\n",
    "                if car_region:\n",
    "                    self.car_count += 1\n",
    "                    self.counter_label.configure(text=f\"Cars: {self.car_count}\")\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)\n",
    "                img = Image.fromarray(rgb_frame)\n",
    "                img = img.resize((640, 360), Image.Resampling.LANCZOS)\n",
    "                img_tk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "                self.video_label.configure(image=img_tk, text=\"\")\n",
    "                self.video_label.image = img_tk\n",
    "            else:\n",
    "                self.log_message(\"‚ö†Ô∏è Frame read failed - reconnecting\")\n",
    "                self.root.after(1000, self.reconnect_camera)\n",
    "                return\n",
    "\n",
    "        except Exception as e:\n",
    "            self.log_message(f\"‚ùå Video error: {str(e)[:60]}\")\n",
    "            self.root.after(1000, self.reconnect_camera)\n",
    "            return\n",
    "\n",
    "        if self.detector.is_running:\n",
    "            self.root.after(55, self.process_video)\n",
    "\n",
    "    def reconnect_camera(self):\n",
    "        self.log_message(\"üîÑ Reconnecting...\")\n",
    "        self.stop_detection()\n",
    "        self.root.after(2000, self.start_detection)\n",
    "\n",
    "# -------------------------\n",
    "# main\n",
    "# -------------------------\n",
    "def main():\n",
    "    try:\n",
    "        root = ctk.CTk()\n",
    "        app = LicensePlateGUI(root)\n",
    "\n",
    "        window_width = 720\n",
    "        window_height = 480\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        x_position = screen_width - window_width - 10\n",
    "        y_position = 10\n",
    "        root.geometry(f\"{window_width}x{window_height}+{x_position}+{y_position}\")\n",
    "\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"Application error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007d643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
